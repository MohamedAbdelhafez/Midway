{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.994400024414\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import numpy as np\n",
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,currentdir+\"/Packages2\") \n",
    "from core.adam import *\n",
    "\n",
    "import tensorflow as tf\n",
    "def AWGN(steps, nbar, n_to_power):\n",
    "    noise  = np.random.normal(size= steps)\n",
    "    amp = nbar * n_to_power\n",
    "    noise = np.sqrt(amp) *noise\n",
    "    return noise\n",
    "gIs = np.transpose(np.concatenate((np.load(\"gtrajs_10ns.npy\"),np.load(\"gtrajs_10ns_1.npy\")), axis = 1))\n",
    "eIs = np.transpose(np.concatenate((np.load(\"etrajs_10ns.npy\"),np.load(\"etrajs_10ns_1.npy\")), axis = 1))\n",
    "\n",
    "\n",
    "num_traj = len(gIs)\n",
    "steps = len(gIs[0])\n",
    "for kk in range (num_traj):\n",
    "    gIs[kk] = gIs[kk] + AWGN(steps, 0, 0.2)\n",
    "    eIs[kk] = eIs[kk] + AWGN(steps, 0, 0.2)\n",
    "\n",
    "num_train = int(3*num_traj/4)\n",
    "g_train = gIs[0:num_train ]\n",
    "e_train = eIs[0:num_train ]\n",
    "g_test = gIs[num_train :]\n",
    "e_test = eIs[num_train:]\n",
    "\n",
    "g_labels = []\n",
    "e_labels = []\n",
    "for ii in range (num_traj):\n",
    "    \n",
    "    g_labels.append([1,0])\n",
    "    e_labels.append([0,1])\n",
    "\n",
    "g_train_labels = g_labels[0:num_train ]\n",
    "e_train_labels = e_labels[0:num_train ]\n",
    "g_test_labels = g_labels[num_train: ]\n",
    "e_test_labels = e_labels[num_train: ]\n",
    "all_train = np.concatenate((g_train,e_train))\n",
    "all_train_labels = np.concatenate((g_train_labels,e_train_labels))\n",
    "all_test = np.concatenate((g_test,e_test))\n",
    "all_test_labels = np.concatenate((g_test_labels,e_test_labels))\n",
    "\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "all_train, all_train_labels = unison_shuffled_copies(all_train, all_train_labels)\n",
    "all_test, all_test_labels = unison_shuffled_copies(all_test, all_test_labels)\n",
    "\n",
    "#ratios = np.linspace(0.1,1,100)\n",
    "ratios = [1]\n",
    "acs = []\n",
    "steps_0 = steps\n",
    "all_train_0 = all_train\n",
    "all_test_0 = all_test\n",
    "for r in ratios:\n",
    "    ratio = r\n",
    "    steps = int(ratio*steps_0)\n",
    "    all_train = all_train_0[:,0:steps]\n",
    "\n",
    "    all_test = all_test_0[:,0:steps]\n",
    "\n",
    "\n",
    "    rate = 0.5\n",
    "    x = tf.placeholder(tf.float32, [None, steps])\n",
    "    W = tf.Variable(tf.zeros([steps, 2]))\n",
    "    b = tf.Variable(tf.zeros([2]))\n",
    "    m = tf.Variable(tf.zeros([steps,2]))\n",
    "    y = tf.matmul(tf.square(x),m) + tf.matmul(x, W) + b\n",
    "    y =  tf.matmul(x, W) + b\n",
    "    y_ = tf.placeholder(tf.float32, [None, 2])\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "    opt = AdamOptimizer(learning_rate = rate, y = y )\n",
    "    train_step = opt.minimize(cross_entropy)\n",
    "    sess = tf.InteractiveSession(config = tf.ConfigProto(device_count = {'GPU': 0}))\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    sess.run(train_step, feed_dict={x: all_train, y_: all_train_labels})\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    ac, res, inpu  = (sess.run([accuracy,y,y_], feed_dict={x: all_test,\n",
    "                                      y_: all_test_labels}))\n",
    "    acs.append(2*ac -1)\n",
    "    print (2*ac-1)\n",
    "    \n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters Defined\n",
      "Using 3 Taylor terms and 0 Scaling & Squaring terms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:281: DeprecationWarning: elementwise != comparison failed; this will raise an error in the future.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os,sys,inspect\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "\n",
    "#from core.Convergence import Convergence\n",
    "#from core.run_session import run_session\n",
    "\n",
    "\n",
    "import random as rd\n",
    "import time\n",
    "import math\n",
    "\n",
    "from tensorflow.python.framework import function\n",
    "from tensorflow.python.framework import ops\n",
    "from time import sleep\n",
    "from numpy.random import random_sample\n",
    "\n",
    "def get_avg(av,average_path,iterations):\n",
    "    #Averaging trajectory gradients\n",
    "    a1 = iterations * average_path\n",
    "    a2 = np.add(av,a1)\n",
    "    return np.divide(a2,(iterations + 1))\n",
    "\n",
    "def dressed_unitary(U,v,dressed_id):\n",
    "    # get unitary matrix in dressed basis\n",
    "    conversion_U = sort_ev(v,dressed_id)\n",
    "    return np.dot(np.dot(conversion_U,U),np.conjugate(np.transpose(conversion_U)))\n",
    "\n",
    "def get_dressed_info(H0):\n",
    "    # assign index of the dressed state according to the overall with bare state\n",
    "    w_c, v_c = la.eig(H0)\n",
    "    dressed_id=[]\n",
    "    for ii in range(len(v_c)):\n",
    "        index = np.argmax(np.abs(v_c[:, ii]))\n",
    "        if index not in dressed_id:\n",
    "            dressed_id.append(index)\n",
    "        else:\n",
    "            temp = (np.abs(v_c[:, ii])).tolist()\n",
    "            while index in dressed_id:\n",
    "                temp[index] = 0\n",
    "                index = np.argmax(temp)\n",
    "            dressed_id.append(index)\n",
    "            \n",
    "    return w_c, v_c, dressed_id\n",
    "\n",
    "def qft(N):\n",
    "    # quantum fourier transform operator\n",
    "    phase = 2.0j * np.pi / (2**N)\n",
    "    L, M = np.meshgrid(np.arange(2**N), np.arange(2**N))\n",
    "    L = np.exp(phase * (L * M))\n",
    "    q = 1.0 / np.sqrt(2**N) * L\n",
    "    return q\n",
    "    \n",
    "def hamming_distance(x):\n",
    "    tot = 0\n",
    "    while x:\n",
    "        tot += 1\n",
    "        x &= x - 1\n",
    "    return tot\n",
    "\n",
    "def Hadamard (N=1):\n",
    "    # Hadamard gate\n",
    "    Had = (2.0 ** (-N / 2.0)) * np.array([[((-1) ** hamming_distance(i & j))\n",
    "                                      for i in range(2 ** N)]\n",
    "                                     for j in range(2 ** N)])\n",
    "    return Had\n",
    "\n",
    "def concerned(N,levels):\n",
    "    concern = []\n",
    "    for ii in range (levels**N):\n",
    "        ii_b = Basis(ii,N,levels)\n",
    "        if is_binary(ii_b):\n",
    "            concern.append(ii)\n",
    "    return concern\n",
    "        \n",
    "def is_binary(num):\n",
    "    flag = True\n",
    "    for c in num: \n",
    "        if c!='0' and c!='1':\n",
    "            flag = False\n",
    "            break\n",
    "    return flag\n",
    "    \n",
    "def transmon_gate(gate,levels):\n",
    "    N = int(np.log2(len(gate)))\n",
    "    result = np.identity(levels**N,dtype=complex)\n",
    "    for ii in range (len(result)):\n",
    "        for jj in range(len(result)):\n",
    "            ii_b = Basis(ii,N,levels)\n",
    "            jj_b = Basis(jj,N,levels)\n",
    "            if is_binary(ii_b) and is_binary(jj_b):\n",
    "                result[ii,jj]=gate[int(ii_b, 2),int(jj_b, 2)]\n",
    "                \n",
    "    return result\n",
    "def rz(theta):\n",
    "    return [[np.exp(-1j * theta / 2), 0],[0, np.exp(1j * theta / 2)]]\n",
    "def rx (theta):\n",
    "    return [[np.cos(theta / 2), -1j * np.sin(theta / 2)],\n",
    "                     [-1j * np.sin(theta / 2), np.cos(theta / 2)]]\n",
    "\n",
    "\n",
    "def Bin(a,N):\n",
    "    a_bin = np.binary_repr(a)\n",
    "    while len(a_bin) < N:\n",
    "        a_bin = '0'+a_bin\n",
    "    return a_bin\n",
    "\n",
    "def baseN(num,b,numerals=\"0123456789abcdefghijklmnopqrstuvwxyz\"):\n",
    "    return ((num == 0) and numerals[0]) or (baseN(num // b, b, numerals).lstrip(numerals[0]) + numerals[num % b])\n",
    "\n",
    "def Basis(a,N,r):\n",
    "    a_new = baseN(a,r)\n",
    "    while len(a_new) < N:\n",
    "        a_new = '0'+a_new\n",
    "    return a_new\n",
    "    \n",
    "    \n",
    "def kron_all(op,num,op_2): \n",
    "    # returns an addition of sth like xii + ixi + iix for op =x and op_2 =i\n",
    "    total = np.zeros([len(op)**num,len(op)**num])\n",
    "    a=op\n",
    "    for jj in range(num):\n",
    "        if jj != 0:\n",
    "            a = op_2\n",
    "        else:\n",
    "            a = op\n",
    "            \n",
    "        for ii in range(num-1):\n",
    "            if (jj - ii) == 1:\n",
    "                \n",
    "                b = op\n",
    "            else:\n",
    "                b = op_2\n",
    "            a = np.kron(a,b)\n",
    "        total = total + a\n",
    "    return a    \n",
    "\n",
    "def multi_kron(op,num): \n",
    "    #returns xx...x\n",
    "    a=op\n",
    "    for ii in range(num-1):\n",
    "        a = np.kron(a,op)\n",
    "    return a\n",
    "\n",
    "def append_separate_krons(op,name,num,state_num,Hops,Hnames,ops_max_amp,amp=4.0): \n",
    "    #appends xii,ixi,iix separately\n",
    "    string = name\n",
    "    I_q = np.identity(state_num)\n",
    "    x = 1\n",
    "    y = 1\n",
    "    z = 1\n",
    "    X1 = op\n",
    "    while(x < num):\n",
    "        X1 = np.kron(X1, I_q)\n",
    "        x = x + 1\n",
    "    Hops.append(X1)\n",
    "    ops_max_amp.append(amp)\n",
    "    x = 1\n",
    "    while(x < num):\n",
    "        string = string + 'i'\n",
    "        x = x+1\n",
    "    Hnames.append(string)\n",
    "\n",
    "    x = 1\n",
    "\n",
    "    while(x < num):\n",
    "        X1 = I_q\n",
    "        string = 'i'\n",
    "        while(y<num):\n",
    "            if(y==x):\n",
    "                X1 = np.kron(X1, op)\n",
    "                y = y + 1\n",
    "                string = string + name\n",
    "            else:\n",
    "                X1 = np.kron(X1, I_q)\n",
    "                y = y + 1\n",
    "                string = string + 'i'\n",
    "        x = x + 1\n",
    "        y=1\n",
    "        Hops.append(X1)\n",
    "        ops_max_amp.append(amp)\n",
    "        Hnames.append(string)\n",
    "    return Hops,Hnames,ops_max_amp\n",
    "\n",
    "def nn_chain_kron(op, op_I, qubit_num, qubit_state_num): \n",
    "    # nearest neighbour kron: e.g. xxii + ixxi + iixx\n",
    "    op_list = ['I']*(qubit_num-2)\n",
    "    op_list = ['OP','OP'] + op_list\n",
    "    \n",
    "    \n",
    "    a_all = np.zeros([qubit_state_num**qubit_num,qubit_state_num**qubit_num])\n",
    "    for ii in range(qubit_num-1):\n",
    "        \n",
    "        if op_list[0] == 'I':\n",
    "            a = op_I\n",
    "        else:\n",
    "            a = op\n",
    "            \n",
    "        for kk in range(1,qubit_num):\n",
    "            if op_list[kk] == 'I':\n",
    "                b = op_I\n",
    "            else:\n",
    "                b = op\n",
    "            a = np.kron(a,b)\n",
    "        \n",
    "        a_all = a_all + a\n",
    "        \n",
    "        op_list = [op_list[-1]] + op_list[:-1]\n",
    "        \n",
    "    \n",
    "    return a_all\n",
    "\n",
    "\n",
    "def sort_ev(v,dressed_id):\n",
    "    # sort the eigenstates according to bare states\n",
    "    v_sorted=[]\n",
    "    \n",
    "    for ii in range (len(dressed_id)):\n",
    "        v1 = v[:,get_state_index(ii,dressed_id)]\n",
    "        v_sorted.append(v1)\n",
    "    \n",
    "    return np.transpose(np.reshape(v_sorted, [len(dressed_id),len(dressed_id)]))\n",
    "\n",
    "def get_state_index(bareindex,dressed_id):\n",
    "    # get the index of dressed state, with maximum overlap with the corresponding bare state\n",
    "    if len(dressed_id) > 0:\n",
    "        return dressed_id.index(bareindex)\n",
    "    else:\n",
    "        return bareindex\n",
    "    \n",
    "def c_to_r_mat(M):\n",
    "    # complex to real isomorphism for matrix\n",
    "    return np.asarray(np.bmat([[M.real,-M.imag],[M.imag,M.real]]))\n",
    "\n",
    "def c_to_r_vec(V):\n",
    "    # complex to real isomorphism for vector\n",
    "    new_v =[]\n",
    "    new_v.append(V.real)\n",
    "    new_v.append(V.imag)\n",
    "    return np.reshape(new_v,[2*len(V)])\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "class SystemParameters:\n",
    "\n",
    "    def __init__(self,H0,Hops,Hnames,U,U0,total_time,steps,states_concerned_list,dressed_info,maxA, draw,initial_guess, show_plots,Unitary_error,state_transfer,no_scaling,reg_coeffs, save, file_path, Taylor_terms,use_gpu,use_inter_vecs,sparse_H,\n",
    "                sparse_U,sparse_K, c_ops,trajectories, do_all, expect_op):\n",
    "        # Input variable\n",
    "        self.sparse_U = sparse_U\n",
    "        self.sparse_H = sparse_H\n",
    "        self.sparse_K = sparse_K\n",
    "        self.use_inter_vecs = use_inter_vecs\n",
    "        self.use_gpu = use_gpu\n",
    "        self.Taylor_terms = Taylor_terms\n",
    "        self.dressed_info = dressed_info\n",
    "        self.reg_coeffs = reg_coeffs\n",
    "        self.file_path = file_path\n",
    "        self.state_transfer = state_transfer\n",
    "        self.no_scaling = no_scaling\n",
    "        self.save = save\n",
    "        self.H0_c = H0\n",
    "        self.ops_c = Hops\n",
    "        self.ops_max_amp = maxA\n",
    "        self.Hnames = Hnames\n",
    "        self.Hnames_original = Hnames #because we might rearrange them later if we have different timescales \n",
    "        self.total_time = total_time\n",
    "        self.steps = steps\n",
    "        self.show_plots = show_plots\n",
    "        self.Unitary_error= Unitary_error\n",
    "        self.trajectories = trajectories\n",
    "        self.c_ops = c_ops\n",
    "        self.traj = False\n",
    "        self.do_all = do_all\n",
    "        self.expect_op = expect_op\n",
    "        self.expect = False\n",
    "        if self.expect_op != []:\n",
    "            self.expect = True\n",
    "\n",
    "\n",
    "        if initial_guess is not None:\n",
    "            # transform initial_guess to its corresponding base value\n",
    "            self.u0 = initial_guess\n",
    "            self.u0_base = np.zeros_like(self.u0)\n",
    "            for ii in range (len(self.u0_base)):\n",
    "                self.u0_base[ii]= self.u0[ii]/self.ops_max_amp[ii]\n",
    "                if max(self.u0_base[ii])> 1.0:\n",
    "                    raise ValueError('Initial guess has strength > max_amp for op %d' % (ii) )\n",
    "            self.u0_base = np.arcsin(self.u0_base) #because we take the sin of weights later\n",
    "                \n",
    "                \n",
    "\n",
    "            \n",
    "        else:\n",
    "            self.u0 =[]\n",
    "        self.states_concerned_list = states_concerned_list\n",
    "\n",
    "        self.is_dressed = False\n",
    "        self.U0_c = U0\n",
    "        self.initial_unitary = c_to_r_mat(U0) #CtoRMat is converting complex matrices to their equivalent real (double the size) matrices\n",
    "        if self.expect:\n",
    "            self.expect_op = c_to_r_mat(self.expect_op)\n",
    "        \n",
    "        if draw is not None:\n",
    "            self.draw_list = draw[0]\n",
    "            self.draw_names = draw[1]\n",
    "        else:\n",
    "            self.draw_list = []\n",
    "            self.draw_names = []\n",
    "        \n",
    "        \n",
    "        if dressed_info !=None:\n",
    "            self.v_c = dressed_info['eigenvectors']\n",
    "            self.dressed_id = dressed_info['dressed_id']\n",
    "            self.w_c = dressed_info['eigenvalues']\n",
    "            self.is_dressed = dressed_info['is_dressed']\n",
    "            self.H0_diag=np.diag(self.w_c)\n",
    "            \n",
    "        self.init_system()\n",
    "        self.init_vectors()\n",
    "        \n",
    "        if self.c_ops !=None:\n",
    "            self.traj = True\n",
    "            self.state_transfer = True\n",
    "            if len(U) != len(states_concerned_list):\n",
    "                full_U = U\n",
    "                U=[]\n",
    "                for ii in range(len(states_concerned_list)):\n",
    "                    U.append(np.dot(full_U,self.initial_vectors_c[ii]))\n",
    "        \n",
    "        if self.state_transfer == False:\n",
    "            self.target_unitary = c_to_r_mat(U)\n",
    "        else:\n",
    "            self.target_vectors=[]\n",
    "            self.target_vectors_c=[]\n",
    "\n",
    "            for target_vector_c in U:\n",
    "                self.target_vector = c_to_r_vec(target_vector_c)\n",
    "                self.target_vectors.append(self.target_vector)\n",
    "                self.target_vectors_c.append(target_vector_c)\n",
    "        \n",
    "        if self.traj:\n",
    "            self.cdaggerc=[]\n",
    "            self.c_ops_real=[]\n",
    "            \n",
    "                   \n",
    "            #ceating the effective hamiltonian that describes the evolution of states if no jumps occur\n",
    "            for ii in range (len(self.c_ops)):\n",
    "                cdaggerc_c = np.dot(np.transpose(np.conjugate(self.c_ops[ii])),self.c_ops[ii])\n",
    "                self.c_ops_real.append(c_to_r_mat(self.c_ops[ii]))\n",
    "                self.cdaggerc.append(c_to_r_mat(cdaggerc_c))\n",
    "                self.H0_c= self.H0_c + ((0-1j)/2)* ( cdaggerc_c)\n",
    "                \n",
    "        self.init_operators()\n",
    "        self.init_one_minus_gaussian_envelope()\n",
    "        self.init_guess()\n",
    "\n",
    "    def approx_expm(self,M,exp_t, scaling_terms): \n",
    "        #approximate the exp at the beginning to estimate the number of taylor terms and scaling and squaring needed\n",
    "        U=np.identity(len(M),dtype=M.dtype)\n",
    "        Mt=np.identity(len(M),dtype=M.dtype)\n",
    "        factorial=1.0 #for factorials\n",
    "        \n",
    "        for ii in range(1,exp_t):\n",
    "            factorial*=ii\n",
    "            Mt=np.dot(Mt,M)\n",
    "            U+=Mt/((2.**float(ii*scaling_terms))*factorial) #scaling by 2**scaling_terms\n",
    "\n",
    "        \n",
    "        for ii in range(scaling_terms):\n",
    "            U=np.dot(U,U) #squaring scaling times\n",
    "        \n",
    "        return U\n",
    "    \n",
    "    def approx_exp(self,M,exp_t, scaling_terms): \n",
    "        # the scaling and squaring of matrix exponential with taylor expansions\n",
    "        U=1.0\n",
    "        Mt=1.0\n",
    "        factorial=1.0 #for factorials\n",
    "        \n",
    "        for ii in range(1,exp_t):\n",
    "            factorial*=ii\n",
    "            Mt=M*Mt\n",
    "            U+=Mt/((2.**float(ii*scaling_terms))*factorial) #scaling by 2**scaling_terms\n",
    "\n",
    "        \n",
    "        for ii in range(scaling_terms):\n",
    "            U=np.dot(U,U) #squaring scaling times\n",
    "        \n",
    "        return U\n",
    "    \n",
    "    def Choose_exp_terms(self, d): \n",
    "        #given our hamiltonians and a number of scaling/squaring, we determine the number of Taylor terms\n",
    "        \n",
    "\n",
    "        exp_t = 30 #maximum\n",
    "\n",
    "        H=self.H0_c\n",
    "        U_f = self.U0_c\n",
    "        for ii in range (len(self.ops_c)):\n",
    "            H = H + self.ops_max_amp[ii]*self.ops_c[ii]\n",
    "        if d == 0:\n",
    "            self.scaling = max(int(2*np.log2(np.max(np.abs(-(0+1j) * self.dt*H)))),0) \n",
    "\n",
    "        else:\n",
    "            self.scaling += d\n",
    "\n",
    "        if self.state_transfer or self.no_scaling:\n",
    "            self.scaling =0\n",
    "        while True:\n",
    "\n",
    "            if len(self.H0_c) < 10:\n",
    "                for ii in range (self.steps):\n",
    "                    U_f = np.dot(U_f,self.approx_expm((0-1j)*self.dt*H, exp_t, self.scaling))\n",
    "                Metric = np.abs(np.trace(np.dot(np.conjugate(np.transpose(U_f)), U_f)))/(self.state_num)\n",
    "            else:\n",
    "                max_term = np.max(np.abs(-(0+1j) * self.dt*H))\n",
    "                \n",
    "                Metric = 1 + self.steps *np.abs((self.approx_exp(max_term, exp_t, self.scaling) - np.exp(max_term))/np.exp(max_term))\n",
    "\n",
    "            if exp_t == 3:\n",
    "                break\n",
    "            if np.abs(Metric - 1.0) < self.Unitary_error:\n",
    "                exp_t = exp_t-1\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        return exp_t\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    def init_system(self):\n",
    "        self.dt = float(self.total_time)/self.steps        \n",
    "        self.state_num= len(self.H0_c)\n",
    "        \n",
    "        \n",
    "    def init_vectors(self):\n",
    "        # initialized vectors used for propagation\n",
    "        self.initial_vectors=[]\n",
    "        self.initial_vectors_c=[]\n",
    "\n",
    "        for state in self.states_concerned_list:\n",
    "            if self.is_dressed:\n",
    "                self.initial_vector_c= self.v_c[:,get_state_index(state,self.dressed_id)]\n",
    "            else:\n",
    "                self.initial_vector_c=np.zeros(self.state_num)\n",
    "                self.initial_vector_c[state]=1\n",
    "            \n",
    "            self.initial_vectors_c.append(self.initial_vector_c)\n",
    "            self.initial_vector = c_to_r_vec(self.initial_vector_c)\n",
    "\n",
    "            self.initial_vectors.append(self.initial_vector)\n",
    "        \n",
    "        \n",
    "\n",
    "    def init_operators(self):\n",
    "        # Create operator matrix in numpy array\n",
    "\n",
    "        self.ops=[]\n",
    "        for op_c in self.ops_c:\n",
    "            op = c_to_r_mat(-1j*self.dt*op_c)\n",
    "            self.ops.append(op)\n",
    "        \n",
    "        self.ops_len = len(self.ops)\n",
    "\n",
    "        self.H0 = c_to_r_mat(-1j*self.dt*self.H0_c)\n",
    "        self.identity_c = np.identity(self.state_num)\n",
    "        self.identity = c_to_r_mat(self.identity_c)\n",
    "        \n",
    "        if self.Taylor_terms is None:\n",
    "            self.exps =[]\n",
    "            self.scalings = []\n",
    "            if self.state_transfer or self.no_scaling:\n",
    "                comparisons = 1\n",
    "            else:\n",
    "                comparisons = 6\n",
    "            d = 0\n",
    "            while comparisons >0:\n",
    "\n",
    "                self.exp_terms = self.Choose_exp_terms(d)\n",
    "                self.exps.append(self.exp_terms)\n",
    "                self.scalings.append(self.scaling)\n",
    "                comparisons = comparisons -1\n",
    "                d = d+1\n",
    "            self.complexities = np.add(self.exps,self.scalings)\n",
    "            a = np.argmin(self.complexities)\n",
    "\n",
    "            self.exp_terms = self.exps[a]\n",
    "            self.scaling = self.scalings[a]\n",
    "        else:\n",
    "            self.exp_terms = self.Taylor_terms[0]\n",
    "            self.scaling = self.Taylor_terms[1]\n",
    "            \n",
    "        \n",
    "        \n",
    "        print (\"Using \"+ str(self.exp_terms) + \" Taylor terms and \"+ str(self.scaling)+\" Scaling & Squaring terms\")\n",
    "        \n",
    "        i_array = np.eye(2*self.state_num)\n",
    "        op_matrix_I=i_array.tolist()\n",
    "        \n",
    "        self.H_ops = []\n",
    "        for op in self.ops:\n",
    "            self.H_ops.append(op)\n",
    "        self.matrix_list = [self.H0]\n",
    "        for ii in range(self.ops_len):\n",
    "            self.matrix_list = self.matrix_list + [self.H_ops[ii]]\n",
    "        \n",
    "        \n",
    "        self.matrix_list = np.array(self.matrix_list)\n",
    "        \n",
    "    def init_one_minus_gaussian_envelope(self):\n",
    "        # Generating the Gaussian envelope that pulses should obey\n",
    "        one_minus_gauss = []\n",
    "        offset = 0.0\n",
    "        overall_offset = 0.01\n",
    "        opsnum=self.ops_len\n",
    "        for ii in range(opsnum):\n",
    "            constraint_shape = np.ones(self.steps)- self.gaussian(np.linspace(-2,2,self.steps)) - offset\n",
    "            constraint_shape = constraint_shape * (constraint_shape>0)\n",
    "            constraint_shape = constraint_shape + overall_offset* np.ones(self.steps)\n",
    "            one_minus_gauss.append(constraint_shape)\n",
    "\n",
    "\n",
    "        self.one_minus_gauss = np.array(one_minus_gauss)\n",
    "\n",
    "\n",
    "    def gaussian(self,x, mu = 0. , sig = 1. ):\n",
    "        return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))\n",
    "\n",
    "    def init_guess(self):\n",
    "        # initail guess for control field\n",
    "        if self.u0 != []:\n",
    "            \n",
    "            self.ops_weight_base = np.reshape(self.u0_base, [self.ops_len,self.steps])\n",
    "        else:\n",
    "            initial_mean = 0\n",
    "            index = 0\n",
    "            \n",
    "            initial_stddev = (1./np.sqrt(self.steps))\n",
    "            self.ops_weight_base = np.random.normal(initial_mean, initial_stddev, [self.ops_len ,self.steps])\n",
    "        \n",
    "        self.raw_shape = np.shape(self.ops_weight_base)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Defining time scales\n",
    "total_time = 5\n",
    "steps = 50\n",
    "state_transfer = True\n",
    "RWA = True\n",
    "RFT = True\n",
    "\n",
    "#Defining H0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "qubit_state_num = 2\n",
    "\n",
    "fq= 4.6/(2*np.pi)\n",
    "kappa = 0.05\n",
    "gamma = 0.001\n",
    "g = 0.05\n",
    "\n",
    "mode_state_num = 5\n",
    "#g = 2.*np.pi*0.1 #GHz\n",
    "fc = 5.0/(2*np.pi) #GHz\n",
    "state_num = qubit_state_num * mode_state_num\n",
    "if RFT:\n",
    "    fq = fq-fc\n",
    "    fc = 0\n",
    "    \n",
    "wc = 2*np.pi*fc\n",
    "wa = 2*np.pi*fq\n",
    "\n",
    "\n",
    "alpha = 0.224574\n",
    "ens = np.array([ 2*np.pi*ii*(fq - 0.5*(ii-1)*alpha) for ii in np.arange(qubit_state_num)])\n",
    "H0q = np.kron(np.identity(mode_state_num),np.diag(ens))\n",
    "\n",
    "a   = np.kron(np.diag(np.sqrt(np.arange(1,mode_state_num)),1),np.identity(qubit_state_num))\n",
    "adag   = np.kron(np.diag(np.sqrt(np.arange(1,mode_state_num)),-1),np.identity(qubit_state_num))\n",
    "sm = np.kron(np.identity(mode_state_num),np.diag(np.sqrt(np.arange(1,qubit_state_num)),1))\n",
    "smdag = np.kron(np.identity(mode_state_num),np.diag(np.sqrt(np.arange(1,qubit_state_num)),-1))\n",
    "\n",
    "if RWA:\n",
    "     H0 = wc * np.dot(adag,a) + H0q + g * (np.dot(adag,sm) + np.dot(a,smdag))\n",
    "else:\n",
    "     H0 = wc * np.dot(adag,a) + H0q +  g * np.dot((adag + a),(sm + smdag))\n",
    "#Defining Forbidden sates\n",
    "\n",
    "\n",
    "#Defining Concerned states (starting states)\n",
    "psi0=[0,1]\n",
    "\n",
    "#Defining states to include in the drawing of occupation\n",
    "states_draw_list = [0,1,2]\n",
    "states_draw_names = ['g0','e0','g1']\n",
    "\n",
    "\n",
    "\n",
    "U =[]\n",
    "U1 = np.zeros(state_num,dtype=complex)\n",
    "U1[1]=1\n",
    "U1[0]=0\n",
    "U.append(U1)\n",
    "U2 = np.zeros(state_num,dtype=complex)\n",
    "U2[0]=1\n",
    "U.append(U2)\n",
    "    \n",
    "\n",
    "#Defining U0 (Initial)\n",
    "q_identity = np.identity(qubit_state_num)\n",
    "U0= q_identity\n",
    "\n",
    "#Defining control Hs\n",
    "IX = a + adag\n",
    "IY = (0+1j)* (a-adag)\n",
    "Hops = [IX]\n",
    "ops_max_amp = [0.05]\n",
    "Hnames =['HI']\n",
    "\n",
    "#Defining convergence parameters\n",
    "max_iterations = 5000\n",
    "decay = max_iterations/2\n",
    "convergence = {'rate':0.005, 'update_step':10, 'max_iterations':max_iterations,\\\n",
    "               'conv_target':1e-6,'learning_rate_decay':decay}\n",
    "reg_coeffs = {'envelope' : 0,  'dwdt':0,'d2wdt2':0}\n",
    "\n",
    "\n",
    "c_ops=[]\n",
    "c_ops.append(np.sqrt(gamma)*sm)\n",
    "c_ops.append(np.sqrt(kappa)*a)\n",
    "\n",
    "u0 = None\n",
    "\n",
    "print (\"Parameters Defined\")\n",
    "\n",
    "\n",
    "\n",
    "      \n",
    "draw = [states_draw_list,states_draw_names]\n",
    "                    \n",
    "show_plots = False\n",
    "initial_guess = u0\n",
    "use_gpu = False,\n",
    "unitary_error = 1e-4\n",
    "maxA=ops_max_amp\n",
    "method ='Adam'\n",
    "expect_op = IX\n",
    "file_name='JC'\n",
    "trajectories = 300\n",
    "do_all_traj = False,\n",
    "data_path = None\n",
    "save = False\n",
    "use_inter_vecs=True\n",
    "\n",
    "def get_inner_product(sys_para,psi1,psi2, num_vecs):\n",
    "    #Take 2 states psi1,psi2, calculate their overlap, for single vector\n",
    "    state_num=sys_para.state_num\n",
    "\n",
    "    psi_1_real = (psi1[0:state_num])\n",
    "    psi_1_imag = (psi1[state_num:2*state_num])\n",
    "    psi_2_real = (psi2[0:state_num])\n",
    "    psi_2_imag = (psi2[state_num:2*state_num])\n",
    "    # psi1 has a+ib, psi2 has c+id, we wanna get Sum ((ac+bd) + i (bc-ad)) magnitude\n",
    "    with tf.name_scope('inner_product'):\n",
    "        ac = tf.multiply(psi_1_real,psi_2_real)\n",
    "        bd = tf.multiply(psi_1_imag,psi_2_imag)\n",
    "        bc = tf.multiply(psi_1_imag,psi_2_real)\n",
    "        ad = tf.multiply(psi_1_real,psi_2_imag)\n",
    "        reals = tf.square(tf.add(tf.reduce_sum(ac),tf.reduce_sum(bd)))\n",
    "        imags = tf.square(tf.subtract(tf.reduce_sum(bc),tf.reduce_sum(ad)))\n",
    "        norm = tf.add(reals,imags)\n",
    "    return norm\n",
    "\n",
    "def get_loss_list(sys_para,psi1,psi2):\n",
    "    state_num=sys_para.state_num\n",
    "\n",
    "    psi_1_real = (psi1[0:state_num,:])\n",
    "    psi_1_imag = (psi1[state_num:2*state_num,:])\n",
    "    psi_2_real = (psi2[0:state_num,:])\n",
    "    psi_2_imag = (psi2[state_num:2*state_num,:])\n",
    "    # psi1 has a+ib, psi2 has c+id, we wanna get Sum ((ac+bd) + i (bc-ad)) magnitude\n",
    "\n",
    "    ac = tf.reduce_sum(tf.multiply(psi_1_real,psi_2_real),0)\n",
    "    bd = tf.reduce_sum(tf.multiply(psi_1_imag,psi_2_imag),0)\n",
    "    bc = tf.reduce_sum(tf.multiply(psi_1_imag,psi_2_real),0)\n",
    "    ad = tf.reduce_sum(tf.multiply(psi_1_real,psi_2_imag),0)\n",
    "    ac_bd = tf.square(tf.add(ac,bd))\n",
    "    bc_ad = tf.square(tf.subtract(bc,ad))\n",
    "\n",
    "    loss_list = tf.add(ac_bd,bc_ad)\n",
    "    return loss_list\n",
    "\n",
    "def get_inner_product_2D(sys_para,psi1,psi2, num_vecs):\n",
    "    #Take 2 states psi1,psi2, calculate their overlap, for arbitrary number of vectors\n",
    "    # psi1 and psi2 are shaped as (2*state_num, number of vectors)\n",
    "    state_num=sys_para.state_num\n",
    "\n",
    "\n",
    "    psi_1_real = (psi1[0:state_num,:])\n",
    "    psi_1_imag = (psi1[state_num:2*state_num,:])\n",
    "    psi_2_real = (psi2[0:state_num,:])\n",
    "    psi_2_imag = (psi2[state_num:2*state_num,:])\n",
    "    # psi1 has a+ib, psi2 has c+id, we wanna get Sum ((ac+bd) + i (bc-ad)) magnitude\n",
    "    with tf.name_scope('inner_product'):\n",
    "        ac = tf.reduce_sum(tf.multiply(psi_1_real,psi_2_real),0)\n",
    "        bd = tf.reduce_sum(tf.multiply(psi_1_imag,psi_2_imag),0)\n",
    "        bc = tf.reduce_sum(tf.multiply(psi_1_imag,psi_2_real),0)\n",
    "        ad = tf.reduce_sum(tf.multiply(psi_1_real,psi_2_imag),0)\n",
    "\n",
    "        ac_bd = tf.square(tf.add(ac,bd))\n",
    "        bc_ad = tf.square(tf.subtract(bc,ad))\n",
    "        reals = tf.reduce_sum(ac_bd) # first trace inner product of all vectors, then squared\n",
    "        imags = tf.reduce_sum(bc_ad)\n",
    "        norm = (tf.add(reals,imags))/(tf.cast(num_vecs,tf.float32))\n",
    "    return norm\n",
    "\n",
    "def get_inner_product_3D(sys_para,psi1,psi2, num_vecs):\n",
    "    #Take 2 states psi1,psi2, calculate their overlap, for arbitrary number of vectors and timesteps\n",
    "    # psi1 and psi2 are shaped as (2*state_num, time_steps, number of vectors)\n",
    "    state_num=sys_para.state_num\n",
    "\n",
    "    psi_1_real = (psi1[0:state_num,:])\n",
    "    psi_1_imag = (psi1[state_num:2*state_num,:])\n",
    "    psi_2_real = (psi2[0:state_num,:])\n",
    "    psi_2_imag = (psi2[state_num:2*state_num,:])\n",
    "    # psi1 has a+ib, psi2 has c+id, we wanna get Sum ((ac+bd) + i (bc-ad)) magnitude\n",
    "    with tf.name_scope('inner_product'):\n",
    "        ac = tf.reduce_sum(tf.multiply(psi_1_real,psi_2_real),0)\n",
    "        bd = tf.reduce_sum(tf.multiply(psi_1_imag,psi_2_imag),0)\n",
    "        bc = tf.reduce_sum(tf.multiply(psi_1_imag,psi_2_real),0)\n",
    "        ad = tf.reduce_sum(tf.multiply(psi_1_real,psi_2_imag),0)\n",
    "        reals = tf.reduce_sum(tf.square(tf.reduce_sum(tf.add(ac,bd),1)))\n",
    "        # first trace inner product of all vectors, then squared, then sum contribution of all time steps\n",
    "        imags = tf.reduce_sum(tf.square(tf.reduce_sum(tf.subtract(bc,ad),1)))\n",
    "        norm = (tf.add(reals,imags))/(len(sys_para.states_concerned_list)**2)\n",
    "    return norm\n",
    "\n",
    "def get_avgd_inner_product ( sys_para, psi1, psi2, start, end):\n",
    "    state_num=sys_para.state_num\n",
    "\n",
    "\n",
    "    psi_1_real = (psi1[0:state_num,start:end])\n",
    "    psi_1_imag = (psi1[state_num:2*state_num,start:end])\n",
    "    psi_2_real = (psi2[0:state_num,start:end])\n",
    "    psi_2_imag = (psi2[state_num:2*state_num,start:end])\n",
    "    # psi1 has a+ib, psi2 has c+id, we wanna get Sum ((ac+bd) + i (bc-ad)) magnitude\n",
    "    with tf.name_scope('inner_product'):\n",
    "        ac = tf.reduce_sum(tf.multiply(psi_1_real,psi_2_real),0)\n",
    "        bd = tf.reduce_sum(tf.multiply(psi_1_imag,psi_2_imag),0)\n",
    "        bc = tf.reduce_sum(tf.multiply(psi_1_imag,psi_2_real),0)\n",
    "        ad = tf.reduce_sum(tf.multiply(psi_1_real,psi_2_imag),0)\n",
    "\n",
    "        ac_bd = tf.add(ac,bd)\n",
    "        bc_ad = tf.subtract(bc,ad)\n",
    "        reals = tf.reduce_sum(ac_bd)/tf.cast((end-start), tf.float32) # first trace inner product of all vectors, then squared\n",
    "        imags = tf.reduce_sum(bc_ad)/tf.cast((end-start), tf.float32)\n",
    "\n",
    "    return reals, imags\n",
    "def my_print(text):\n",
    "    sys.stdout.write(str(text)+'\\n')\n",
    "    sys.stdout.flush()\n",
    "def expect (sys_para, num_trajs,  op, psis):\n",
    "    result = []\n",
    "    psis2 = tf.matmul(tf.cast(op,tf.float32),psis)\n",
    "    if num_trajs[0] !=0:\n",
    "\n",
    "        expect1 = get_avgd_inner_product (sys_para, psis, psis2, 0, num_trajs[0])\n",
    "        if not sys_para.do_all:\n",
    "            result.append(expect1)\n",
    "    else:\n",
    "        expect1 = 0\n",
    "    if num_trajs[1] !=0:\n",
    "        expect2 = get_avgd_inner_product (sys_para, psis, psis2, num_trajs[0], num_trajs[0] + num_trajs[1])\n",
    "        if not sys_para.do_all:\n",
    "            result.append(expect2)\n",
    "    else:\n",
    "        expect2 = 0\n",
    "    if sys_para.do_all:\n",
    "        return expect1, expect2\n",
    "    else:\n",
    "        return tf.stack(result)\n",
    "\n",
    "def normalize(sys_para, psi, num_vecs):\n",
    "    state_num=sys_para.state_num\n",
    "    new_norms = tf.reshape(get_norms(sys_para, psi, num_vecs),[num_vecs])\n",
    "    weights = 1/tf.sqrt(new_norms)\n",
    "    x = []\n",
    "    for ii in range (2*state_num):\n",
    "        x.append(weights)\n",
    "    return tf.multiply(psi,tf.stack(x))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_norms(sys_para, psi, num_vecs):\n",
    "    state_num=sys_para.state_num\n",
    "    psi1 = tf.reshape(psi,[2*state_num,num_vecs])\n",
    "    return tf.reduce_sum(tf.square(psi1),0)\n",
    "\n",
    "def get_norm(sys_para, psi):\n",
    "    state_num=sys_para.state_num\n",
    "    psi1 = tf.reshape(psi,[2*state_num,1])\n",
    "    return tf.reduce_sum(tf.square(psi1),0)\n",
    "def get_one_random(sys_para, num_trajs, start,end,index):\n",
    "    vec_type = tf.constant(0)\n",
    "    sums = []\n",
    "    s = 0\n",
    "    for jj in range (len(sys_para.initial_vectors)):\n",
    "        #create a list of their summed probabilities\n",
    "        s=s+num_trajs[jj]\n",
    "        sums=tf.concat([sums,tf.reshape(s,[1])],0)\n",
    "\n",
    "    r2 = tf.cast(index,tf.int32)\n",
    "    rvector=r2 * tf.ones_like(sums)\n",
    "    cond2= tf.greater_equal(sums,rvector)\n",
    "    b=tf.where(cond2)\n",
    "    final =tf.reshape(b[0,:],[])\n",
    "    return tf.random_uniform([1],tf.gather(start,final),tf.gather(end,final))\n",
    "\n",
    "\n",
    "\n",
    "def get_random(sys_para,num_trajs,  start,end,length=1):\n",
    "\n",
    "    #Returns a random number between 0 & 1 to tell jumps when to occur\n",
    "    ii =0\n",
    "    rand = []\n",
    "    for initial_vector in sys_para.initial_vectors:\n",
    "        new = tf.random_uniform([num_trajs[ii]],start[ii],end[ii])\n",
    "        if rand == []:\n",
    "            rand = new\n",
    "        else:\n",
    "            rand = tf.concat([rand,new],0)\n",
    "        ii = ii+1\n",
    "\n",
    "    #rand=tf.random_uniform([length],start,end)\n",
    "    return rand\n",
    "\n",
    "def divide(needed,max_traj):\n",
    "    returned = []\n",
    "\n",
    "    end = False\n",
    "\n",
    "    while not end:\n",
    "        summation = 0\n",
    "        trial = np.zeros_like(needed)\n",
    "        flag = True\n",
    "\n",
    "        for ii in range (len(needed)):\n",
    "            if flag and ((summation + needed[ii]) <= max_traj):\n",
    "                summation = summation + needed[ii]\n",
    "                trial[ii] = needed[ii]\n",
    "                if ii == len(needed)-1:\n",
    "                    end = True\n",
    "            else:\n",
    "\n",
    "                trial[ii] = max_traj - summation\n",
    "                summation = max_traj\n",
    "                flag = False\n",
    "        returned.append(trial)\n",
    "        needed = needed-trial\n",
    "    return returned\n",
    "    \n",
    "\n",
    "\n",
    "# start time\n",
    "grape_start_time = time.time()\n",
    "freq_unit = \"GHz\"\n",
    "# set timing unit used for plotting\n",
    "freq_time_unit_dict = {\"GHz\": \"ns\", \"MHz\": \"us\",\"KHz\":\"ms\",\"Hz\":\"s\"}\n",
    "time_unit = freq_time_unit_dict[freq_unit]\n",
    "\n",
    "# make sparse_{H,U,K} False if use_gpu is True, as GPU Sparse Matmul is not supported yet.\n",
    "if use_gpu:\n",
    "    sparse_H = False\n",
    "    sparse_U = False\n",
    "    sparse_K = False\n",
    "\n",
    "file_path = None\n",
    "\n",
    "\n",
    "\n",
    "if U0 is None:\n",
    "    U0 = np.identity(len(H0))\n",
    "if convergence is None:\n",
    "    convergence = {'rate':0.01, 'update_step':100, 'max_iterations':5000,'conv_target':1e-8,'learning_rate_decay':2500}\n",
    "\n",
    "\n",
    "if maxA is None:\n",
    "    if initial_guess is None:\n",
    "        maxAmp = 4*np.ones(len(Hops))\n",
    "    else:\n",
    "        maxAmp = 1.5*np.max(np.abs(initial_guess))*np.ones(len(Hops))\n",
    "else:\n",
    "    maxAmp = maxA\n",
    "\n",
    "Taylor_terms = None\n",
    "if state_transfer:\n",
    "    no_scaling = True\n",
    "else:\n",
    "    no_scaling = False\n",
    "dressed_info = None\n",
    "# pass in system parameters\n",
    "sys_para = SystemParameters(H0,Hops,Hnames,U,U0,total_time,steps,psi0,dressed_info,maxAmp, draw,initial_guess,  show_plots,unitary_error,state_transfer,no_scaling,reg_coeffs, save, file_path, Taylor_terms, use_gpu, use_inter_vecs,sparse_H,sparse_U,sparse_K, c_ops, trajectories, do_all_traj, expect_op)\n",
    "\n",
    "#run_python = Python_evolve(sys_para)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building graph:\n",
      "Worker running\n",
      "Operators weight initialized.\n",
      "Trajectories Initialized\n",
      "Training loss initialized.\n",
      "Optimizer initialized.\n",
      "Graph  built!\n",
      "Entering iterations_\n"
     ]
    }
   ],
   "source": [
    "norms=[]\n",
    "jumps=[]\n",
    "\n",
    "input_num = len(sys_para.Hnames) +1\n",
    "taylor_terms = sys_para.exp_terms \n",
    "scaling = sys_para.scaling\n",
    "num_vecs = len(sys_para.initial_vectors)\n",
    "print (\"Building graph:\")\n",
    "sys.stdout.flush()\n",
    "\n",
    "print (\"Worker running\")\n",
    "sys.stdout.flush()\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():  \n",
    "              \n",
    "\n",
    "\n",
    "\n",
    "    if sys_para.traj:\n",
    "        tf_c_ops = tf.constant(np.reshape(sys_para.c_ops_real,[len(sys_para.c_ops),2*sys_para.state_num,2*sys_para.state_num]),dtype=tf.float32)\n",
    "        tf_cdagger_c = tf.constant(np.reshape(sys_para.cdaggerc,[len(sys_para.c_ops),2*sys_para.state_num,2*sys_para.state_num]),dtype=tf.float32)\n",
    "\n",
    "        if sys_para.expect:\n",
    "            expect_op = tf.constant(sys_para.expect_op)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    tf_one_minus_gaussian_envelope = tf.constant(sys_para.one_minus_gauss,dtype=tf.float32, name = 'Gaussian')\n",
    "\n",
    "\n",
    "\n",
    "    if sys_para.traj:\n",
    "        tf_initial_vectors=[]\n",
    "        num_trajs = [150,150]\n",
    "        for initial_vector in sys_para.initial_vectors:\n",
    "            tf_initial_vector = tf.constant(initial_vector,dtype=tf.float32)\n",
    "\n",
    "            for ii in range(150):\n",
    "                tf_initial_vectors.append(tf_initial_vector)\n",
    "        packed_initial_vectors = tf.transpose(tf.stack(tf_initial_vectors))\n",
    "        num_vecs = 300\n",
    "        \n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "    #H0_weight = tf.Variable(tf.ones([sys_para.steps]), trainable=False) #Just a vector of ones needed for the kernel\n",
    "    weights_unpacked=[] #will collect all weights here\n",
    "    ops_weight_base = tf.Variable(tf.constant(sys_para.ops_weight_base, dtype = tf.float32), dtype=tf.float32,name =\"weights_base\")\n",
    "\n",
    "    ops_weight = tf.sin(ops_weight_base,name=\"weights\")\n",
    "    for ii in range (sys_para.ops_len):\n",
    "        weights_unpacked.append(sys_para.ops_max_amp[ii]*ops_weight[ii,:])\n",
    "\n",
    "    #print len(sys_para.ops_max_amp)\n",
    "    H_weights = tf.stack(weights_unpacked,name=\"packed_weights\")\n",
    "\n",
    "\n",
    "\n",
    "    print (\"Operators weight initialized.\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "\n",
    "    global_step = tf.get_variable('global_step', [], \n",
    "                      initializer = tf.constant_initializer(0), \n",
    "                      trainable = False,\n",
    "                      dtype = tf.int32)\n",
    "\n",
    "\n",
    "    jump_vs = []\n",
    "    tf_matrix_list = tf.constant(sys_para.matrix_list,dtype=tf.float32)\n",
    "    # Create a trajectory for each initial state\n",
    "    Evolution_states=[]\n",
    "    inter_vecs=[]\n",
    "    inter_lst = []\n",
    "    #start = tf.placeholder(tf.float32,shape=[])\n",
    "    #end = tf.placeholder(tf.float32,shape=[])\n",
    "    start = tf.placeholder(tf.float32,shape=[len(sys_para.initial_vectors)])\n",
    "    end = tf.placeholder(tf.float32,shape=[len(sys_para.initial_vectors)])\n",
    "    psi0 = packed_initial_vectors\n",
    "    old_psi = psi0\n",
    "    new_psi = psi0\n",
    "    norms = tf.ones([num_vecs],dtype = tf.float32)\n",
    "    r=get_random(sys_para,num_trajs,  start,end,num_vecs)\n",
    "    operator = tf_c_ops[0] # temporary\n",
    "    expects = []\n",
    "    inter_vecs_list=[]\n",
    "    inter_vecs_list.append(old_psi)\n",
    "    all_jumps= []\n",
    "    all_norms = []\n",
    "    all_norms.append(norms)\n",
    "    vecs = tf.cast(num_vecs, tf.int64)\n",
    "    for ii in np.arange(0,sys_para.steps):\n",
    "        old_psi = new_psi\n",
    "\n",
    "        new_psi =   old_psi/tf.reduce_sum(H_weights[:,ii])\n",
    "        #new_psi = matvecexp_op(H_weights[:,ii],tf_matrix_list,old_psi)\n",
    "        new_norms = tf.reshape(get_norms(sys_para, new_psi, num_vecs),[num_vecs])\n",
    "\n",
    "        norms = tf.multiply(norms,new_norms)\n",
    "        all_norms.append(norms)\n",
    "\n",
    "        cond= tf.less(norms,r)\n",
    "        a=tf.where(cond)\n",
    "        state_num=sys_para.state_num\n",
    "        reshaped_new = tf.reshape(new_psi,[2*state_num*num_vecs])\n",
    "\n",
    "        c = tf.constant(0)\n",
    "        def while_condition(c,old,new,norms,randoms):\n",
    "            return tf.less(c, tf.size(a))\n",
    "        def jump_fn(c,old,new,norms,randoms):\n",
    "\n",
    "\n",
    "            index = tf.reshape(tf.gather(a,c),[])\n",
    "            idx = []\n",
    "\n",
    "            for kk in range (2*state_num):\n",
    "                idx.append(index + kk*vecs)\n",
    "\n",
    "            vector = tf.gather(reshaped_new,idx)\n",
    "            #vector = tf.gather(tf.transpose(old),index)\n",
    "\n",
    "\n",
    "            #####\n",
    "\n",
    "\n",
    "            if len(sys_para.c_ops)>1:\n",
    "                weights=[]\n",
    "                sums=[]\n",
    "                s=0\n",
    "                for ii in range (len(sys_para.c_ops)):\n",
    "\n",
    "                    temp=tf.matmul(tf.transpose(tf.reshape(vector,[2*state_num,1])),tf_cdagger_c[ii,:,:])\n",
    "                    temp2=tf.matmul(temp,tf.reshape(vector,[2*state_num,1])) #get the jump expectation value\n",
    "                    weights=tf.concat([weights,tf.reshape(temp2,[1])],0)\n",
    "                weights=tf.abs(weights/tf.reduce_sum(tf.abs(weights))) #convert them to probabilities\n",
    "\n",
    "                for jj in range (len(sys_para.c_ops)):\n",
    "                    #create a list of their summed probabilities\n",
    "                    s=s+weights[jj]\n",
    "                    sums=tf.concat([sums,tf.reshape(s,[1])],0)\n",
    "\n",
    "                r2 = tf.random_uniform([1],0,1)\n",
    "                #tensorflow conditional graphing, checks for the first time a summed probability exceeds the random number\n",
    "                rvector=r2 * tf.ones_like(sums)\n",
    "                cond2= tf.greater_equal(sums,rvector)\n",
    "                b=tf.where(cond2)\n",
    "                final =tf.reshape(b[0,:],[])\n",
    "                #final = tf.gather(b,0)\n",
    "\n",
    "                #apply the chosen jump operator\n",
    "                propagator2 = tf.reshape(tf.gather(tf_c_ops,final),[2*sys_para.state_num,2*sys_para.state_num])\n",
    "            else:\n",
    "                propagator2 = tf.reshape(tf_c_ops,[2*sys_para.state_num,2*sys_para.state_num])\n",
    "            inter_vec_temp2 = tf.matmul(propagator2,tf.reshape(vector,[2*sys_para.state_num,1]))\n",
    "            norm2 = get_norm(sys_para, inter_vec_temp2)\n",
    "            inter_vec_temp2 = inter_vec_temp2 / tf.sqrt(norm2)\n",
    "\n",
    "            #delta = tf.reshape(inter_vec_temp2 - tf.gather(tf.transpose(new),index),[2*sys_para.state_num])\n",
    "\n",
    "            new_vector = tf.reshape(tf.gather(tf.reshape(new,[2*state_num*num_vecs]),idx),[2*sys_para.state_num])\n",
    "            inter_vec_temp2 = tf.reshape(inter_vec_temp2,[2*sys_para.state_num])\n",
    "            #delta = inter_vec_temp2 \n",
    "            delta = inter_vec_temp2-new_vector\n",
    "            indices=[]\n",
    "            for jj in range (2*sys_para.state_num):\n",
    "                indices.append([jj,index])\n",
    "\n",
    "            values = delta\n",
    "            shape = tf.cast(tf.stack([2*sys_para.state_num,num_vecs]),tf.int64)\n",
    "            Delta = tf.SparseTensor(indices, values, shape)\n",
    "            new = new + tf.sparse_tensor_to_dense(Delta)\n",
    "\n",
    "\n",
    "            values = tf.reshape(1 - tf.gather(norms,index),[1])\n",
    "            shape = tf.cast(tf.stack([num_vecs]),tf.int64)\n",
    "            Delta_norm = tf.SparseTensor(tf.reshape(index,[1,1]), values, shape)\n",
    "            norms = norms + tf.sparse_tensor_to_dense(Delta_norm)\n",
    "\n",
    "            #new_random = get_one_random(start, end,index)\n",
    "            new_random =tf.random_uniform([1],0,1)\n",
    "            values = tf.reshape(new_random - tf.gather(randoms,index),[1])\n",
    "            #shape = tf.stack([num_vecs])\n",
    "            Delta_norm = tf.SparseTensor(tf.reshape(index,[1,1]), values, shape)\n",
    "            randoms = randoms + tf.sparse_tensor_to_dense(Delta_norm)\n",
    "\n",
    "            #####\n",
    "\n",
    "            return [tf.add(c, 1),old,new,norms,randoms]\n",
    "\n",
    "        wh,old_psi,new_psi,norms,r = tf.while_loop(while_condition, jump_fn, [c,old_psi,new_psi,norms,r])\n",
    "        all_jumps.append(wh)\n",
    "\n",
    "\n",
    "        new_psi = normalize(sys_para, new_psi, num_vecs)\n",
    "\n",
    "        inter_vecs_list.append(new_psi)\n",
    "        if sys_para.expect:\n",
    "\n",
    "            expects.append(expect(sys_para, num_trajs, expect_op, new_psi))\n",
    "\n",
    "    inter_vecs_packed = tf.stack(inter_vecs_list, axis=1)\n",
    "    inter_vecs = inter_vecs_packed\n",
    "    all_norms = tf.stack(all_norms)\n",
    "    if sys_para.expect:\n",
    "        if sys_para.do_all:\n",
    "            expectations = tf.stack(expects, axis=1)\n",
    "        else:\n",
    "            expectations = tf.stack(expects)\n",
    "    else:\n",
    "        expectations = 0\n",
    "\n",
    "    #####\n",
    "\n",
    "    #inter_vecs_packed.set_shape([2*sys_para.state_num,sys_para.steps,num_vecs] )\n",
    "    #inter_vecs2 = tf.unstack(inter_vecs_packed, axis = 2)\n",
    "    #indices = tf.stack(indices)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #inter_vec = tf.reshape(psi0,[2*sys_para.state_num,1],name=\"initial_vector\")\n",
    "    #psi0 = inter_vec\n",
    "\n",
    "\n",
    "    all_jumps = tf.stack(all_jumps)\n",
    "    jumps.append(jumps)\n",
    "    #jumps = tf.stack(jumps)\n",
    "    #for tf_initial_vector in tf_initial_vectors:\n",
    "        #Evolution_states.append(One_Trajectory(tf_initial_vector)) #returns the final state of the trajectory\n",
    "    packed = inter_vecs_packed\n",
    "    print (\"Trajectories Initialized\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "    if sys_para.state_transfer == False:\n",
    "\n",
    "        final_vecs = tf.matmul(final_state, packed_initial_vectors)\n",
    "\n",
    "        loss = 1-get_inner_product_2D(sys_para, final_vecs,target_vecs, num_vecs)\n",
    "\n",
    "    else:\n",
    "        #loss = tf.constant(0.0, dtype = tf.float32)\n",
    "        final_state = inter_vecs_packed[:,sys_para.steps,:]\n",
    "        a = []\n",
    "        for ii in range (sys_para.steps):\n",
    "            a.append(tf.constant((sys_para.steps-ii), dtype = tf.float32))\n",
    "        accelerate = tf.stack(a)\n",
    "        accelerate = tf.ones([sys_para.steps])\n",
    "        #\n",
    "        if sys_para.expect:\n",
    "\n",
    "            Il1 = tf.reduce_sum(expectations[:,0,0])  \n",
    "            Il2 = -tf.reduce_sum(expectations[:,1,0])\n",
    "            Il = Il1 + Il2\n",
    "            Il1d = tf.gradients(Il1, [ops_weight_base])[0]\n",
    "            Il2d = tf.gradients(Il2, [ops_weight_base])[0]\n",
    "            loss = - tf.square(Il)\n",
    "            quad = tf.gradients(loss, [ops_weight_base])[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        unitary_scale = get_inner_product_2D(sys_para, final_state,final_state, num_vecs)\n",
    "\n",
    "\n",
    "    reg_loss = loss\n",
    "\n",
    "    print (\"Training loss initialized.\")\n",
    "    sys.stdout.flush()\n",
    "    learning_rate = tf.placeholder(tf.float32,shape=[])\n",
    "    opt = tf.train.GradientDescentOptimizer(learning_rate = learning_rate)\n",
    "    \n",
    "\n",
    "    #Here we extract the gradients of the pulses\n",
    "    grad = opt.compute_gradients(reg_loss)\n",
    "\n",
    "    grad_pack = tf.stack([g for g, _ in grad])\n",
    "    var = [v for _,v in grad]\n",
    "\n",
    "    grads =[tf.nn.l2_loss(g) for g, _ in grad]\n",
    "    grad_squared = tf.reduce_sum(tf.stack(grads))\n",
    "\n",
    "\n",
    "    gradients =[g for g, _ in grad]\n",
    "    avg_grad = tf.placeholder(tf.float32, shape = [1,len(sys_para.ops),sys_para.steps])\n",
    "\n",
    "    new_grad = zip(tf.unstack(avg_grad),var)\n",
    "    #new_grad = grad\n",
    "\n",
    "    if sys_para.traj:\n",
    "        #optimizer = opt.apply_gradients(new_grad, global_step = global_step)\n",
    "        #optimizer = opt.apply_gradients(grad, global_step = global_step)\n",
    "        optimizer = opt.minimize(reg_loss, global_step = global_step)\n",
    "\n",
    "\n",
    "    else:\n",
    "        optimizer = opt.apply_gradients(grad)\n",
    "\n",
    "\n",
    "    #optimizer = opt.apply_gradients(grad)\n",
    "\n",
    "    print (\"Optimizer initialized.\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print (\"Graph  built!\")\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    traj_num = sys_para.trajectories\n",
    "    max_traj = 1000\n",
    "    num_psi0 = len(sys_para.initial_vectors)\n",
    "    needed_traj = []\n",
    "    for kk in range (num_psi0):\n",
    "        needed_traj.append(traj_num)\n",
    "    jump_traj = np.sum(needed_traj)\n",
    "    num_batches = 2\n",
    "    num_traj_batch = int(traj_num/num_batches)\n",
    "    lrate = 0.005\n",
    "    fd_dict = {learning_rate: lrate, start: np.zeros([num_psi0]), end: np.ones([num_psi0])}\n",
    "    print (\"Entering iterations_\")\n",
    "    sys.stdout.flush()\n",
    "    #if is_chief:\n",
    "        #sleep(0.01)\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iteration:  out of 2 with 150 jump trajectories\n",
      " Iteration:  out of 2 with 150 jump trajectories\n",
      " Iteration:  out of 2 with 150 jump trajectories\n",
      " Iteration:  out of 2 with 150 jump trajectories\n",
      " Iteration:  out of 2 with 150 jump trajectories\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    for ii in range(5):\n",
    "\n",
    "\n",
    "        my_print('\\r'+' Iteration: ' +\" out of \"+str(num_batches)+ \" with \"+str(num_traj_batch)+\" jump trajectories\")\n",
    "        #sys.stdout.flush()\n",
    "\n",
    "        #nos, exs, l1d,l2d,  q, l1, l2, int_vecs,step = sess.run([norms, expectations, Il1d, Il2d,quad, Il1, Il2, inter_vecs, global_step], feed_dict=fd_dict)\n",
    "        _ = sess.run([optimizer], feed_dict=fd_dict)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
